import time
import os
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from urllib.parse import unquote
import re
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading


def setup_driver(download_path=None):
    """webdriver_managerë¡œ Chrome ë“œë¼ì´ë²„ ìë™ ì„¤ì •"""
    if download_path is None:
        download_path = os.path.join(os.getcwd(), "downloads")

    if not os.path.exists(download_path):
        os.makedirs(download_path)

    chrome_options = Options()
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)

    print("ChromeDriver ìë™ ì„¤ì¹˜ ì¤‘...")
    service = Service(ChromeDriverManager().install())

    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

    return driver


def create_section_folders(base_path):
    """ì„¹ì…˜ë³„ í´ë” ìƒì„±"""

    section_info = {
        "01_ë”ë§ì€ê¸°íšŒ": {
            "name": "ë” ë§ì€ ê¸°íšŒ",
            "range": (1, 49),
            "description": "ê²½ì œì„±ì¥, ìŠ¤íƒ€íŠ¸ì—…, ì¼ìë¦¬ ì°½ì¶œ ê´€ë ¨ ê³µì•½",
        },
        "02_ì£¼íƒêµí†µì¼ìë¦¬": {
            "name": "ì£¼íƒ, êµí†µ, ì¼ìë¦¬ê°€ ìœ ì¾Œí•œ ê²½ê¸°",
            "range": (50, 91),
            "description": "ì£¼ê±°, êµí†µ, ë…¸ë™ ê´€ë ¨ ê³µì•½",
        },
        "03_ë¬¸í™”ì˜ˆìˆ ì—¬ê°€": {
            "name": "ë¬¸í™”ì˜ˆìˆ , ì—¬ê°€ê°€ ì¼ìƒì´ ë˜ëŠ” ê²½ê¸°",
            "range": (92, 116),
            "description": "ë¬¸í™”, ì˜ˆìˆ , ìŠ¤í¬ì¸ , ê´€ê´‘ ê´€ë ¨ ê³µì•½",
        },
        "04_ë”ê³ ë¥¸ê¸°íšŒ": {
            "name": "ë” ê³ ë¥¸ ê¸°íšŒ",
            "range": (117, 203),
            "description": "ë³µì§€, ëŒë´„, ì˜ë£Œ, êµìœ¡ ê´€ë ¨ ê³µì•½",
        },
        "05_ë¶ë¶€í‰í™”ê¸°íšŒ": {
            "name": "ë¶ë¶€ì— ë³€í™”ì™€ í‰í™”ì˜ ê¸°íšŒë¥¼ ë§Œë“œëŠ” ê²½ê¸°",
            "range": (204, 218),
            "description": "ê²½ê¸°ë¶ë¶€ ë°œì „, í‰í™”ê²½ì œ ê´€ë ¨ ê³µì•½",
        },
        "06_ë”ë‚˜ì€ê¸°íšŒ": {"name": "ë” ë‚˜ì€ ê¸°íšŒ", "range": (219, 270), "description": "í–‰ì •í˜ì‹ , í™˜ê²½, ì•ˆì „ ê´€ë ¨ ê³µì•½"},
        "07_ì‚¬íšŒì ê°€ì¹˜": {
            "name": "ì‚¬íšŒì  ê°€ì¹˜, í‰ë“±í•œ ê¸°íšŒê°€ ë³´ì¥ë˜ëŠ” ê²½ê¸°",
            "range": (271, 295),
            "description": "ì‚¬íšŒì ê²½ì œ, í‰ë“±, ê³µì •ê±°ë˜ ê´€ë ¨ ê³µì•½",
        },
    }

    created_folders = {}

    print(f"ğŸ“ ì„¹ì…˜ë³„ í´ë” ìƒì„±: {base_path}")

    for folder_key, info in section_info.items():
        folder_path = os.path.join(base_path, folder_key)
        os.makedirs(folder_path, exist_ok=True)

        readme_path = os.path.join(folder_path, "README.md")
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(f"# {info['name']}\n\n")
            f.write(f"**ê³µì•½ ë²ˆí˜¸**: {info['range'][0]}ë²ˆ ~ {info['range'][1]}ë²ˆ\n\n")
            f.write(f"**ì„¤ëª…**: {info['description']}\n\n")
            f.write(f"**ë‹¤ìš´ë¡œë“œ ì‹œê°„**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        created_folders[folder_key] = {"path": folder_path, "info": info}

        print(f"  âœ… {folder_key} - {info['name']}")

    return created_folders


def determine_section_by_number(pdf_filename):
    """PDF íŒŒì¼ëª…ì—ì„œ ê³µì•½ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ í•´ë‹¹ ì„¹ì…˜ ê²°ì •"""

    match = re.match(r"^(\d+)_", pdf_filename)
    if not match:
        return "00_ë¯¸ë¶„ë¥˜"

    promise_num = int(match.group(1))

    if 1 <= promise_num <= 49:
        return "01_ë”ë§ì€ê¸°íšŒ"
    elif 50 <= promise_num <= 91:
        return "02_ì£¼íƒêµí†µì¼ìë¦¬"
    elif 92 <= promise_num <= 116:
        return "03_ë¬¸í™”ì˜ˆìˆ ì—¬ê°€"
    elif 117 <= promise_num <= 203:
        return "04_ë”ê³ ë¥¸ê¸°íšŒ"
    elif 204 <= promise_num <= 218:
        return "05_ë¶ë¶€í‰í™”ê¸°íšŒ"
    elif 219 <= promise_num <= 270:
        return "06_ë”ë‚˜ì€ê¸°íšŒ"
    elif 271 <= promise_num <= 295:
        return "07_ì‚¬íšŒì ê°€ì¹˜"
    else:
        return "00_ë¯¸ë¶„ë¥˜"


def extract_and_categorize_pdfs(driver, base_path, section_folders):
    """í˜ì´ì§€ì—ì„œ PDF URLì„ ì¶”ì¶œí•˜ê³  ì„¹ì…˜ë³„ë¡œ ë¶„ë¥˜"""

    print("ğŸ” í˜ì´ì§€ì—ì„œ PDF URL ì¶”ì¶œ ë° ë¶„ë¥˜ ì¤‘...")

    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(3)
    driver.execute_script("window.scrollTo(0, 0);")
    time.sleep(2)

    viewer_links = driver.find_elements(By.XPATH, "//a[contains(@href, 'pdfjs/web/viewer.html')]")

    categorized_pdfs = {}

    for section_key in section_folders.keys():
        categorized_pdfs[section_key] = []
    categorized_pdfs["00_ë¯¸ë¶„ë¥˜"] = []

    for link in viewer_links:
        try:
            href = link.get_attribute("href")
            if "file=" in href:
                pdf_url = href.split("file=")[1]
                pdf_url = unquote(pdf_url)
                filename = pdf_url.split("/")[-1]

                if not any(exclude in filename for exclude in ["ê³µì•½ì‹¤ì²œê³„íšì„œ", "ë¶™ì„2"]):
                    section_key = determine_section_by_number(filename)

                    categorized_pdfs[section_key].append({"url": pdf_url, "filename": filename, "viewer_url": href})

        except Exception as e:
            print(f"âš ï¸ PDF ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (ì¤‘ë‹¨ ì‹œ ì¬ì‹œì‘ ê°€ëŠ¥)
    urls_backup_path = os.path.join(base_path, "pdf_urls_backup.json")
    with open(urls_backup_path, "w", encoding="utf-8") as f:
        json.dump(categorized_pdfs, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“Š PDF URL ë°±ì—… ì €ì¥: {urls_backup_path}")

    total_pdfs = 0
    print("\nğŸ“Š ì„¹ì…˜ë³„ PDF ë¶„ë¥˜ ê²°ê³¼:")
    for section_key, pdfs in categorized_pdfs.items():
        if pdfs:
            section_name = section_folders.get(section_key, {}).get("info", {}).get("name", "ë¯¸ë¶„ë¥˜")
            print(f"  ğŸ“‚ {section_key}: {len(pdfs)}ê°œ - {section_name}")
            total_pdfs += len(pdfs)

    print(f"ğŸ¯ ì´ {total_pdfs}ê°œì˜ ê°œë³„ ê³µì•½ PDF ë°œê²¬")

    return categorized_pdfs


def download_single_pdf(pdf_info, section_path, max_retries=5):
    """ë‹¨ì¼ PDF ë‹¤ìš´ë¡œë“œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Referer": "https://governor.gg.go.kr/",
        "Accept": "application/pdf,application/octet-stream,*/*",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
    }

    for attempt in range(max_retries):
        try:
            session = requests.Session()
            session.headers.update(headers)

            # ì ì§„ì  íƒ€ì„ì•„ì›ƒ ì¦ê°€
            timeout = 30 + (attempt * 15)

            response = session.get(pdf_info["url"], stream=True, timeout=timeout, allow_redirects=True)

            if response.status_code == 200:
                file_path = os.path.join(section_path, pdf_info["filename"])

                with open(file_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)

                file_size = os.path.getsize(file_path)

                # íŒŒì¼ í¬ê¸° ê²€ì¦ (ë„ˆë¬´ ì‘ìœ¼ë©´ ì˜¤ë¥˜)
                if file_size < 1000:  # 1KB ì´í•˜ë©´ ë¹„ì •ìƒ
                    os.remove(file_path)
                    raise Exception(f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {file_size} bytes")

                return {"success": True, "filename": pdf_info["filename"], "size": file_size, "attempts": attempt + 1}

            else:
                raise Exception(f"HTTP {response.status_code}")

        except Exception as e:
            error_msg = str(e)

            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2  # 2, 4, 6, 8ì´ˆ ëŒ€ê¸°
                print(f"      âš ï¸ {attempt + 1}ì°¨ ì‹¤íŒ¨: {error_msg[:50]}... ({wait_time}ì´ˆ í›„ ì¬ì‹œë„)")
                time.sleep(wait_time)
                continue
            else:
                return {"success": False, "filename": pdf_info["filename"], "error": error_msg, "attempts": max_retries}

    return {
        "success": False,
        "filename": pdf_info["filename"],
        "error": "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼",
        "attempts": max_retries,
    }


def download_categorized_pdfs_with_retry(categorized_pdfs, section_folders, base_path):
    """ê°œì„ ëœ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ (ì¬ì‹œë„ + ë³‘ë ¬ ì²˜ë¦¬)"""

    print("ğŸ“¥ ì„¹ì…˜ë³„ PDF ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ì¬ì‹œë„ ë¡œì§ ì ìš©)")
    print("=" * 60)

    download_results = {}

    for section_key, pdfs in categorized_pdfs.items():
        if not pdfs:
            continue

        if section_key == "00_ë¯¸ë¶„ë¥˜":
            section_path = os.path.join(base_path, "00_ë¯¸ë¶„ë¥˜")
            os.makedirs(section_path, exist_ok=True)
        else:
            section_path = section_folders[section_key]["path"]

        section_name = section_folders.get(section_key, {}).get("info", {}).get("name", "ë¯¸ë¶„ë¥˜")

        print(f"\nğŸ“‚ {section_key} - {section_name} ({len(pdfs)}ê°œ)")
        print("=" * 50)

        success_count = 0
        failed_files = []

        # ì§„í–‰ ìƒí™© ì €ì¥ì„ ìœ„í•œ íŒŒì¼
        progress_file = os.path.join(section_path, ".download_progress.json")
        completed_files = set()

        # ê¸°ì¡´ ì§„í–‰ ìƒí™© ë¡œë“œ
        if os.path.exists(progress_file):
            try:
                with open(progress_file, "r", encoding="utf-8") as f:
                    progress_data = json.load(f)
                    completed_files = set(progress_data.get("completed", []))
                print(f"  ğŸ“‹ ì´ë¯¸ ì™„ë£Œëœ íŒŒì¼: {len(completed_files)}ê°œ")
            except:
                pass

        # ë‚¨ì€ íŒŒì¼ë“¤ë§Œ ë‹¤ìš´ë¡œë“œ
        remaining_pdfs = [pdf for pdf in pdfs if pdf["filename"] not in completed_files]

        if not remaining_pdfs:
            print(f"  âœ… ì´ë¯¸ ëª¨ë“  íŒŒì¼ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            download_results[section_key] = {"success": len(pdfs), "failed": [], "total": len(pdfs)}
            continue

        print(f"  ğŸ“¥ ë‹¤ìš´ë¡œë“œí•  íŒŒì¼: {len(remaining_pdfs)}ê°œ")

        # ìˆœì°¨ ë‹¤ìš´ë¡œë“œ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        for i, pdf_info in enumerate(remaining_pdfs, 1):
            print(f"  ğŸ“¥ {i:2d}/{len(remaining_pdfs)} {pdf_info['filename']}")

            result = download_single_pdf(pdf_info, section_path)

            if result["success"]:
                print(f"      âœ… ì™„ë£Œ ({result['size']:,} bytes, {result['attempts']}íšŒ ì‹œë„)")
                success_count += 1
                completed_files.add(pdf_info["filename"])

                # ì§„í–‰ ìƒí™© ì €ì¥
                progress_data = {"completed": list(completed_files)}
                with open(progress_file, "w", encoding="utf-8") as f:
                    json.dump(progress_data, f, ensure_ascii=False, indent=2)

            else:
                print(f"      âŒ ì‹¤íŒ¨: {result['error'][:50]}... ({result['attempts']}íšŒ ì‹œë„)")
                failed_files.append(pdf_info["filename"])

            # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
            time.sleep(1)

        # ì™„ë£Œ í›„ ì§„í–‰ ìƒí™© íŒŒì¼ ì‚­ì œ
        if os.path.exists(progress_file):
            os.remove(progress_file)

        total_success = len(completed_files)
        download_results[section_key] = {"success": total_success, "failed": failed_files, "total": len(pdfs)}

        print(f"  ğŸ“Š {section_name}: {total_success}/{len(pdfs)} ì„±ê³µ")
        if failed_files:
            print(f"      âŒ ì‹¤íŒ¨í•œ íŒŒì¼: {len(failed_files)}ê°œ")

    return download_results


def create_retry_script(failed_files, base_path):
    """ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ì„ ì¬ë‹¤ìš´ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""

    if not any(result["failed"] for result in failed_files.values()):
        return

    retry_script_path = os.path.join(base_path, "retry_failed_downloads.py")

    with open(retry_script_path, "w", encoding="utf-8") as f:
        f.write(
            """#!/usr/bin/env python3
# -*- coding: utf-8 -*-
\"\"\"
ì‹¤íŒ¨í•œ PDF íŒŒì¼ë“¤ì„ ì¬ë‹¤ìš´ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ìë™ ìƒì„±ë¨
\"\"\"

import json
import os
import sys

# ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì˜ í•¨ìˆ˜ë“¤ì„ import
# (ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ë‘ê³  ì‹¤í–‰)

def retry_failed_downloads():
    base_path = os.path.dirname(os.path.abspath(__file__))
    urls_backup_path = os.path.join(base_path, "pdf_urls_backup.json")
    
    if not os.path.exists(urls_backup_path):
        print("âŒ PDF URL ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    with open(urls_backup_path, 'r', encoding='utf-8') as f:
        categorized_pdfs = json.load(f)
    
    print("ğŸ”„ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ ì¬ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    # ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ë§Œ ì¶”ì¶œ
    failed_pdfs = {}
"""
        )

        for section_key, result in failed_files.items():
            if result["failed"]:
                f.write(f"    failed_pdfs['{section_key}'] = {result['failed']}\n")

        f.write(
            """
    # ì¬ë‹¤ìš´ë¡œë“œ ë¡œì§ êµ¬í˜„
    # ... (ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë¡œì§ì€ ì›ë³¸ í•¨ìˆ˜ ì¬ì‚¬ìš©)

if __name__ == "__main__":
    retry_failed_downloads()
"""
        )

    print(f"ğŸ”„ ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {retry_script_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("ğŸš€ ê²½ê¸°ë„ ì„¹ì…˜ë³„ ê³µì•½ PDF ë‹¤ìš´ë¡œë” v6.0 (ì•ˆì •í™” ë²„ì „)")
    print("=" * 70)

    base_path = os.path.join(os.getcwd(), "gyeonggi_policies")

    print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ ê¸°ë³¸ ê²½ë¡œ: {base_path}")

    # ê¸°ì¡´ ë°±ì—… íŒŒì¼ì´ ìˆìœ¼ë©´ ì¬ì‹œì‘ ì˜µì…˜ ì œê³µ
    urls_backup_path = os.path.join(base_path, "pdf_urls_backup.json")

    if os.path.exists(urls_backup_path):
        print(f"\nğŸ” ê¸°ì¡´ ë°±ì—… íŒŒì¼ ë°œê²¬: {urls_backup_path}")
        restart = input("ê¸°ì¡´ URL ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()

        if restart == "y":
            print("ğŸ“‹ ë°±ì—… íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë”©...")

            with open(urls_backup_path, "r", encoding="utf-8") as f:
                categorized_pdfs = json.load(f)

            section_folders = create_section_folders(base_path)
            download_results = download_categorized_pdfs_with_retry(categorized_pdfs, section_folders, base_path)

            # ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
            create_retry_script(download_results, base_path)

            print("\nğŸ‰ ì¬ì‹œì‘ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            return

    # ìƒˆë¡œ ì‹œì‘
    section_folders = create_section_folders(base_path)

    print("\nğŸ”§ ChromeDriver ì„¤ì • ì¤‘...")
    driver = setup_driver(base_path)

    try:
        url = "https://governor.gg.go.kr/promises/status/"
        print(f"ğŸŒ í˜ì´ì§€ ì ‘ì†: {url}")

        driver.get(url)
        time.sleep(5)

        categorized_pdfs = extract_and_categorize_pdfs(driver, base_path, section_folders)

        driver.quit()
        print("ğŸ”š ë¸Œë¼ìš°ì € ì¢…ë£Œ")

        download_results = download_categorized_pdfs_with_retry(categorized_pdfs, section_folders, base_path)

        # ì¬ì‹œë„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        create_retry_script(download_results, base_path)

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 70)
        print("ğŸ‰ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

        total_success = sum(result["success"] for result in download_results.values())
        total_files = sum(result["total"] for result in download_results.values())
        total_failed = sum(len(result["failed"]) for result in download_results.values())

        print(f"ğŸ“Š ì „ì²´ ê²°ê³¼: {total_success}/{total_files} ì„±ê³µ ({total_failed}ê°œ ì‹¤íŒ¨)")
        print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ í´ë”: {base_path}")

        if total_failed > 0:
            print(f"\nâš ï¸ ì‹¤íŒ¨í•œ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.")
            print(f"retry_failed_downloads.py ìŠ¤í¬ë¦½íŠ¸ë¡œ ì¬ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # í´ë” ì—´ê¸°
        import platform

        system = platform.system()

        if system == "Darwin":  # macOS
            os.system(f"open '{base_path}'")
        elif system == "Windows":
            os.system(f'explorer "{base_path}"')

        print("ğŸ“ ë‹¤ìš´ë¡œë“œ í´ë”ê°€ ì—´ë ¸ìŠµë‹ˆë‹¤!")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if "driver" in locals():
            driver.quit()


if __name__ == "__main__":
    main()
